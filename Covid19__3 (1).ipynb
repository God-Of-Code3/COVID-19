{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Covid19__3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN31VhU11V9p"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djPm_FO95_6V"
      },
      "source": [
        "import matplotlib\r\n",
        "matplotlib.use(\"Agg\")\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers.core import Dense\r\n",
        "from keras.optimizers import SGD\r\n",
        "from imutils import paths\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import pickle\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "import nibabel as nib\r\n",
        "from scipy import ndimage\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihyu8zja6B0p"
      },
      "source": [
        "MAIN_PATH = \"/content/drive/My Drive/Dataset/\"\r\n",
        "DATASET_PATH = MAIN_PATH + \"Data/\"\r\n",
        "HEALTHY_PATH = DATASET_PATH + \"healthy/\"\r\n",
        "SICK_PATH = DATASET_PATH + \"sick/\"\r\n",
        "TEST_PATH = DATASET_PATH + \"test/\"\r\n",
        "\r\n",
        "COMP_PATH = MAIN_PATH + \"Computed/\"\r\n",
        "HEALTHY_PATH2 = COMP_PATH + \"healthy/\"\r\n",
        "SICK_PATH2 = COMP_PATH + \"sick/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDw_LARH6YE2"
      },
      "source": [
        "random.seed(49)\r\n",
        "Healthy_Paths = os.listdir(HEALTHY_PATH)\r\n",
        "Healthy_Paths = list(map(lambda x: \"healthy/\" + x, Healthy_Paths))\r\n",
        "Sick_Paths = os.listdir(SICK_PATH)\r\n",
        "Sick_Paths = list(map(lambda x: \"sick/\" + x, Sick_Paths))\r\n",
        "random.shuffle(Sick_Paths)\r\n",
        "random.shuffle(Healthy_Paths)\r\n",
        "Paths = Healthy_Paths + Sick_Paths[:204]\r\n",
        "random.shuffle(Paths)\r\n",
        "\r\n",
        "data = []\r\n",
        "labels = []\r\n",
        "min_height = -1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBOXWrlensr5"
      },
      "source": [
        "random.seed(49)\r\n",
        "Healthy_Paths = os.listdir(HEALTHY_PATH2)\r\n",
        "Healthy_Paths = list(map(lambda x: \"healthy/\" + x, Healthy_Paths))\r\n",
        "Sick_Paths = os.listdir(SICK_PATH2)\r\n",
        "Sick_Paths = list(map(lambda x: \"sick/\" + x, Sick_Paths))\r\n",
        "random.shuffle(Sick_Paths)\r\n",
        "random.shuffle(Healthy_Paths)\r\n",
        "Paths = Healthy_Paths + Sick_Paths[:204]\r\n",
        "random.shuffle(Paths)\r\n",
        "\r\n",
        "data = []\r\n",
        "labels = []\r\n",
        "min_height = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z35MXSf3PCT2"
      },
      "source": [
        "def normalize(volume):\r\n",
        "    min = -1000\r\n",
        "    max = 400\r\n",
        "    volume[volume < min] = min\r\n",
        "    volume[volume > max] = max\r\n",
        "    volume = (volume - min) / (max - min)\r\n",
        "    volume = volume.astype(\"float32\")\r\n",
        "    return volume\r\n",
        "\r\n",
        "\r\n",
        "def resize_volume(img):\r\n",
        "    desired_depth = 32\r\n",
        "    desired_width = 128\r\n",
        "    desired_height = 128\r\n",
        "    current_depth = img.shape[-1]\r\n",
        "    current_width = img.shape[0]\r\n",
        "    current_height = img.shape[1]\r\n",
        "    depth = current_depth / desired_depth\r\n",
        "    width = current_width / desired_width\r\n",
        "    height = current_height / desired_height\r\n",
        "    depth_factor = 1 / depth\r\n",
        "    width_factor = 1 / width\r\n",
        "    height_factor = 1 / height\r\n",
        "    img = ndimage.rotate(img, 90, reshape=False)\r\n",
        "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\r\n",
        "    return img\r\n",
        "  \r\n",
        "\r\n",
        "def process_scan(volume):\r\n",
        "    volume = normalize(volume)\r\n",
        "    volume = resize_volume(volume)\r\n",
        "    return volume\r\n",
        "\r\n",
        "def rotate(volume):\r\n",
        "    def scipy_rotate(volume):\r\n",
        "        angles = [-20, -10, -5, 5, 10, 20]\r\n",
        "        angle = random.choice(angles)\r\n",
        "        volume = ndimage.rotate(volume, angle, reshape=False)\r\n",
        "        volume[volume < 0] = 0\r\n",
        "        volume[volume > 1] = 1\r\n",
        "        return volume\r\n",
        "\r\n",
        "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\r\n",
        "    return augmented_volume\r\n",
        "\r\n",
        "\r\n",
        "def train_preprocessing(volume, label):\r\n",
        "    volume = rotate(volume)\r\n",
        "    volume = tf.expand_dims(volume, axis=3)\r\n",
        "    return volume, label\r\n",
        "\r\n",
        "\r\n",
        "def validation_preprocessing(volume, label):\r\n",
        "    volume = tf.expand_dims(volume, axis=3)\r\n",
        "    return volume, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE9FCzmieUc_"
      },
      "source": [
        "COMPRESSION = 4\r\n",
        "\r\n",
        "for i, file_path in enumerate(Paths):\r\n",
        "  img = nib.load(DATASET_PATH + file_path)\r\n",
        "  img = img.get_fdata()\r\n",
        "  img = process_scan(img)\r\n",
        "  new_img = []\r\n",
        "  new_img = np.array(img, dtype=\"float\")\r\n",
        "  new_img = tf.expand_dims(new_img, axis=3)\r\n",
        "  data.append(new_img)\r\n",
        "  with open(MAIN_PATH + \"Computed/\" + file_path + \".pickle\", 'wb') as f:\r\n",
        "    pickle.dump([new_img], f)\r\n",
        "  label = file_path.split(\"/\")[0]\r\n",
        "\r\n",
        "  if label == \"sick\":\r\n",
        "    label = [1, 0]\r\n",
        "  else:\r\n",
        "    label = [0, 1]\r\n",
        "  labels.append(label)\r\n",
        "\r\n",
        "  if min_height == -1 or img.shape[2] < min_height:\r\n",
        "    min_height = img.shape[2]\r\n",
        "  print(str(i) + \"/408 computed\")\r\n",
        "print(data[0].shape)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AfkpL7qn1z-"
      },
      "source": [
        "COMPRESSION = 4\r\n",
        "\r\n",
        "for i, file_path in enumerate(Paths):\r\n",
        "  with open(COMP_PATH + file_path, 'rb') as f:\r\n",
        "    new_img = pickle.load(f)\r\n",
        "    new_img = rotate(new_img)\r\n",
        "    data.append(new_img[0])\r\n",
        "  label = file_path.split(\"/\")[0]\r\n",
        "  if label == \"sick\":\r\n",
        "    label = [1, 0]\r\n",
        "  else:\r\n",
        "    label = [0, 1]\r\n",
        "  labels.append(label)\r\n",
        "  print(str(i) + \"/408 computed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdh93GxtQOYI"
      },
      "source": [
        "with open(MAIN_PATH + \"start_data.pickle\", 'wb') as f:\r\n",
        "  pickle.dump(data, f)\r\n",
        "print(\"Data seved\")\r\n",
        "\r\n",
        "with open(MAIN_PATH + \"start_labels.pickle\", 'wb') as f:\r\n",
        "  pickle.dump(labels, f)\r\n",
        "print(\"Labels seved\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdHm42Tyksfd"
      },
      "source": [
        "\"\"\"print(data[0].shape)\r\n",
        "for i, d in enumerate(data):\r\n",
        "  data[i] = np.resize(d, (int(512 // COMPRESSION), int(512 // COMPRESSION), min_height, 1))\"\"\"\r\n",
        "\r\n",
        "data = np.array(data, dtype=\"float\")\r\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp14J96GfiH7"
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\r\n",
        "                                                  test_size=0.10,\r\n",
        "                                                  random_state=48)\r\n",
        "\r\n",
        "print(\"Dataset prepared\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pShh84U8o28x"
      },
      "source": [
        "print(trainX[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D13L8zV8Y-hK"
      },
      "source": [
        "### АРХИТЕКТУРЫ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kmyo8eDf0cg"
      },
      "source": [
        "from keras.layers import Conv3D, Flatten, Dropout, Activation, MaxPooling3D, MaxPooling2D\r\n",
        "\r\n",
        "model = Sequential() \r\n",
        "\r\n",
        "model.add(Conv3D(32, (3, 3, 3), padding=\"same\", input_shape=(int(512 // COMPRESSION), int(512 // COMPRESSION), trainX[0].shape[2], 1)))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(Conv3D(32, (3, 3, 3), padding=\"same\", activation=\"relu\"))\r\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\"))\r\n",
        "model.add(Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\"))\r\n",
        "\r\n",
        "model.add(MaxPooling3D(pool_size = (2, 2, 2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "\r\n",
        "#model.add(Dense(1024,input_shape=(3072,), activation='sigmoid'))\r\n",
        "model.add(Dense(512, activation='relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4ecIaTFQjBL"
      },
      "source": [
        "Принципиально новая архитектура (нет)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7eB86OFQiMX"
      },
      "source": [
        "from keras.layers import Conv3D, Flatten, Dropout, Activation, MaxPool3D, MaxPooling2D, GlobalAveragePooling3D\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model = Sequential() \r\n",
        "model.add(Conv3D(filters=32, kernel_size=3, padding=\"same\", activation='relu', input_shape=(int(512 // COMPRESSION), int(512 // COMPRESSION), trainX[0].shape[2], 1)))\r\n",
        "model.add(MaxPool3D(pool_size=2))\r\n",
        "model.add(BatchNormalization())\r\n",
        "\r\n",
        "model.add(Conv3D(filters=64, kernel_size=3, padding=\"same\", activation='relu'))\r\n",
        "model.add(MaxPool3D(pool_size=2))\r\n",
        "model.add(BatchNormalization())\r\n",
        "\r\n",
        "model.add(Conv3D(filters=128, kernel_size=3, padding=\"same\", activation='relu'))\r\n",
        "model.add(MaxPool3D(pool_size=2))\r\n",
        "model.add(BatchNormalization())\r\n",
        "\r\n",
        "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation='relu'))\r\n",
        "model.add(MaxPool3D(pool_size=2))\r\n",
        "model.add(BatchNormalization())\r\n",
        "\r\n",
        "model.add(GlobalAveragePooling3D())\r\n",
        "model.add(Dense(units=512, activation='relu'))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "\r\n",
        "model.add(Dense(units=2, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC-70S8_T_af"
      },
      "source": [
        "from keras.layers import Conv3D, Flatten, Dropout, Activation, MaxPooling3D, MaxPooling2D, AveragePooling3D\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Conv3D(32, 5, padding=\"same\", input_shape=(int(512 // COMPRESSION), int(512 // COMPRESSION), trainX[0].shape[2], 1), activation=\"relu\"))\r\n",
        "model.add(AveragePooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "model.add(Conv3D(32, 5, padding=\"same\", activation=\"relu\"))\r\n",
        "model.add(AveragePooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "model.add(Conv3D(32, 5, padding=\"same\", activation=\"relu\"))\r\n",
        "model.add(AveragePooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(512, activation=\"sigmoid\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(256, activation=\"sigmoid\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(128, activation=\"sigmoid\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(2, activation=\"sigmoid\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOY8UFU_4Swx"
      },
      "source": [
        "from keras.layers import Conv3D, Flatten, Dropout, Activation, MaxPooling3D, MaxPooling2D\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "chanDim = -1\r\n",
        "model.add(Conv3D(8, 16, strides=1, padding='same', activation='relu',\r\n",
        "                 kernel_initializer='glorot_normal',\r\n",
        "                 input_shape=(128, 128, trainX[0].shape[2], 1)))\r\n",
        "\r\n",
        "model.add(Conv3D(16, 9, strides=1, padding='same', activation='relu',\r\n",
        "                 kernel_initializer='glorot_normal'))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "\r\n",
        "model.add(Conv3D(8, 9, strides=1, padding='same', activation='relu',\r\n",
        "                 kernel_initializer='glorot_normal'))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(16, activation='relu'))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "model.add(Dense(16, activation='relu'))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "\r\n",
        "model.add(Dense(2, activation='sigmoid'))\r\n",
        "\r\n",
        "print (\"End\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj3Gysu-R0Q8"
      },
      "source": [
        "from keras.layers import Conv3D, Flatten, Dropout, Activation, MaxPooling3D, MaxPooling2D\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "chanDim = -1\r\n",
        "model.add(Conv3D(8, (5, 5, 5), padding=\"same\",\r\n",
        "          input_shape=(int(512 // COMPRESSION), int(512 // COMPRESSION), trainX[0].shape[2], 1)))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "\r\n",
        "model.add(Conv3D(16, (5, 5, 5), padding=\"same\"))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(Conv3D(16, (5, 5, 5), padding=\"same\"))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "\r\n",
        "model.add(Conv3D(32, (7, 7, 7), padding=\"same\"))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(Conv3D(32, (7, 7, 7), padding=\"same\"))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv3D(64, (9, 9, 9), padding=\"same\"))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(Conv3D(64, (9, 9, 9), padding=\"same\"))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(64))\r\n",
        "model.add(Activation(\"relu\"))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Dense(2))\r\n",
        "model.add(Activation(\"softmax\"))\r\n",
        "\r\n",
        "print (\"End\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQjBu03VZNNd"
      },
      "source": [
        "from keras.layers import Conv3D, Flatten, Dropout, Activation, MaxPooling3D, MaxPooling2D\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "chanDim = -1\r\n",
        "model.add(Conv3D(32, 5, strides=4, padding='same', activation='relu',\r\n",
        "                 input_shape=(int(512 // COMPRESSION), int(512 // COMPRESSION), trainX[0].shape[2], 1)))\r\n",
        "model.add(Conv3D(32, 5, padding='same', activation='relu'))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "  \r\n",
        "model.add(Conv3D(64, 3, strides=1, padding='same', activation='sigmoid'))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(Conv3D(64, 3, strides=1, padding='same', activation='sigmoid'))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\r\n",
        "model.add(Conv3D(64, 3, strides=1, padding='same', activation='sigmoid'))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "  \r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(Dropout(0.15))\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(Dropout(0.15))\r\n",
        "  \r\n",
        "model.add(Dense(2, activation='softmax'))\r\n",
        "\r\n",
        "print('End')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UjZfOwLW4yQ"
      },
      "source": [
        "from keras.layers import Conv3D, Flatten, Dropout, Activation, MaxPooling3D, MaxPooling2D, MaxPool3D\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "\r\n",
        "chanDim = -1\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv3D(32 , 8 , strides=4, padding = 'same' , activation = 'relu' , input_shape=(int(512 // COMPRESSION), int(512 // COMPRESSION), trainX[0].shape[2], 1)))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPool3D(pool_size = (2,2, 2)))\r\n",
        "model.add(Conv3D(64 , 16 , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPool3D(pool_size=(2,2,2), strides = 2 , padding = 'same'))\r\n",
        "model.add(Conv3D(64 , 3 , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPool3D(pool_size=(2,2,2), strides = 2 , padding = 'same'))\r\n",
        "model.add(Conv3D(128 , 3 , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPool3D(pool_size=(2,2,2), strides = 2 , padding = 'same'))\r\n",
        "model.add(Conv3D(256 , 3 , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(BatchNormalization(axis=chanDim))\r\n",
        "model.add(MaxPool3D(pool_size=(2,2,2), strides = 2 , padding = 'same'))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(512 , activation = 'relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(512 , activation = 'relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Dense(2 , activation = 'sigmoid'))\r\n",
        "model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7shppGIZFbH"
      },
      "source": [
        "### ОБУЧЕНИЕ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqjxDKWfXJ_a"
      },
      "source": [
        "from keras.optimizers import Adam, RMSprop\r\n",
        "\r\n",
        "EPOCHS = 50\r\n",
        "\r\n",
        "INIT_LR = 0.003\r\n",
        "\r\n",
        "#opt = SGD(lr=INIT_LR, decay=1e-7)\r\n",
        "\r\n",
        "BS = 32\r\n",
        "\r\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / (EPOCHS * 0.5))\r\n",
        "\r\n",
        "#opt = Adam(learning_rate=INIT_LR, beta_1=0.9, beta_2=0.999, amsgrad=False)\r\n",
        "#opt = RMSprop(learning_rate=0.001, rho=0.9)\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\r\n",
        "              metrics=[\"accuracy\"])  #categorial_crosentropy\r\n",
        "\r\n",
        "print (\"Model compiled\")\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMmNFkmSwgAL"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "model = load_model(MAIN_PATH + \"THE_BEST_RESULT__3.h5\")\r\n",
        "BS = 32\r\n",
        "EPOCHS = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oekh52Xl8nX9"
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath=MAIN_PATH + '/THE_BEST_RESULT__3_2.h5', verbose=1, save_best_only=True)\r\n",
        "\r\n",
        "print(trainX[0].shape)\r\n",
        "H = None\r\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY),\r\n",
        "              steps_per_epoch=trainX.shape[0] // BS,\r\n",
        "              epochs=EPOCHS, batch_size=BS,\r\n",
        "              shuffle=True,\r\n",
        "              callbacks=[checkpointer])\r\n",
        "\r\n",
        "print(\"Model trained\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH2oqps0FSt9"
      },
      "source": [
        "N = np.arange(0, EPOCHS)\r\n",
        "plt.style.use(\"seaborn-dark-palette\")\r\n",
        "plt.figure()\r\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\r\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\r\n",
        "plt.title(\"Results\")\r\n",
        "plt.xlabel(\"Epoch #\")\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.legend()\r\n",
        "plt.savefig(MAIN_PATH + \"Loss6.png\")\r\n",
        "\r\n",
        "plt.style.use(\"seaborn-dark-palette\")\r\n",
        "plt.figure()\r\n",
        "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\r\n",
        "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\r\n",
        "plt.title(\"Results\")\r\n",
        "plt.xlabel(\"Epoch #\")\r\n",
        "plt.ylabel(\"Accuracy\")\r\n",
        "plt.legend()\r\n",
        "plt.savefig(MAIN_PATH + \"Accuracy6.png\")\r\n",
        "\r\n",
        "\r\n",
        "print(\"End\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5stNXvh4G77d"
      },
      "source": [
        "model.save(MAIN_PATH + \"Лучшая модель 71 процент.model\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}